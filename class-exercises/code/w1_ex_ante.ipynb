{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 \n",
    "\n",
    "The purpose of this week's exercise is twofold: First, to introduce you to Numpy and making you familiar with the library and some of its pitfalls. Second, you will apply this to estimate the linear model using OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Jupyter Basics) A few things to note about Jupyter Notebook (ipynb files). (1) Notebooks may run cells individually by selecting a cell and using ctrl + enter. (2) Each notebook runs on a kernel which is selected by the user the first time a cell is run. (3) The kernel \"stores\" variables as the code is run. To utilize code in a proceeding cell, it is neccessary to run the previous cell. Be careful with overlapping variable names across cells. It becomes messy to clean up.\n",
    "\n",
    "* The kernel is your installation of Python. Make sure your installation of Python is visible to your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that some of the exercises are purposefully made to return errors. Take the time to identify why they occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A short introduction to Numpy and Linear Algebra (Linalg)\n",
    "First, import all necessary packages. If you are missing a package, you can either install it through your terminal using pip, or an Anaconda terminal using conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # We import the package numpy and name it \"np\"\n",
    "from numpy import linalg as la \n",
    "# We import the subpackage linalg from numpy and name it \"la\". \n",
    "# In most cases, importing a subpackage is not neccessary when the overarching package has been imported, \n",
    "\n",
    "# although lacking dependencies may change functionality in some cases.\n",
    "from numpy import random as random\n",
    "from tabulate import tabulate\n",
    "#(NB if you havent got tabulate yet, install it using !pip install tabulate)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entering matrices manually\n",
    "To create a $1\\times9$ *row* vector write,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "row = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "scalar_x = 5\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a $9\\times1$ *column* vector write,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "col = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9]])\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easier method is to define a row vector, and transpose it. Notice the double [[]]. Try to see what happens if you transpose a row vector using only []."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "col = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9]]).T\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A short note on numpy vectors**\n",
    "Numpy does not treat vectors and matrices the same. A *true* numpy vector has the shape (k,), . The shape of a numpy array is an attribute, how do you call this attribute for the `row` and `col` arrays? What is the shape of the `row.T` array? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n",
      "(9, 1)\n",
      "(1, 9)\n"
     ]
    }
   ],
   "source": [
    "# Call the shape attribute for the row and col vars. Check the shape of col.T\n",
    "# FILL IN HERE\n",
    "\n",
    "print(row.shape)\n",
    "print(col.shape)\n",
    "print(col.T.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a matrix, you combine what you have learned to manually create a $3 \\times 3$ matrix called x, that has the numbers 0 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0,1,2],[3,4,5],[6,7,8]]) # FILL IN HERE\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the same $3 \\times 3$ using `np.arange()` and np.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(8) # FILL IN HERE\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix calculations \n",
    "There are several types of matrix calculations available to us with the numpy library, and we will introduce some here.\n",
    "\n",
    "For matrix **multiplication** you can for the matrices `a` and `b` use `a@b`, `np.dot(a, b)` or `a.dot(b)`\n",
    "\n",
    "Perform matrix multiplication on the following:\n",
    "- `row`$\\cdot$`row'`, `row'`$\\cdot$`row`, `row`$\\cdot$`row`;\n",
    "- `col`$\\cdot$`col'`, `col'`$\\cdot$`col`, `col`$\\cdot$`col`;\n",
    "- `x`$\\cdot$`x`, `row`$\\cdot$`col'`, `col`$\\cdot$`row'`.\n",
    "\n",
    "Does the `row` vector behave as you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n",
      "285\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "print(row@row)\n",
    "print(np.dot(row, row))\n",
    "print(row.dot(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n",
      "[[ 1  2  3  4  5  6  7  8  9]\n",
      " [ 2  4  6  8 10 12 14 16 18]\n",
      " [ 3  6  9 12 15 18 21 24 27]\n",
      " [ 4  8 12 16 20 24 28 32 36]\n",
      " [ 5 10 15 20 25 30 35 40 45]\n",
      " [ 6 12 18 24 30 36 42 48 54]\n",
      " [ 7 14 21 28 35 42 49 56 63]\n",
      " [ 8 16 24 32 40 48 56 64 72]\n",
      " [ 9 18 27 36 45 54 63 72 81]]\n",
      "[[285]]\n"
     ]
    }
   ],
   "source": [
    "print(row@row.T)\n",
    "print(col@col.T)\n",
    "print(col.T@col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "[285]\n",
      "[1 2 3 4 5 6 7 8 9] a 1x9 vector\n",
      "[[1 2 3 4 5 6 7 8 9]] a 1x9 vector\n"
     ]
    }
   ],
   "source": [
    "print(x@x)\n",
    "print(col.T@row)\n",
    "#print(row@col.T) # throws a mismatch error. Multiplies 1x9 with 1x9.\n",
    "print(str(row) + \" a 1x9 vector\")\n",
    "print(str(col.T) + \" a 1x9 vector\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you use `*` and `/` operators on the same pairs as above? Does the `col` vector behave as you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4  9 16 25 36 49 64 81]]\n",
      "[ 1  4  9 16 25 36 49 64 81]\n",
      "[ 1  4  9 16 25 36 49 64 81]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(row*col.T) # no. It simply multiplies the scalars on the column, which isn't what we want.\n",
    "print(row.T*row) # difference between \n",
    "print(row*row) # elementwise multiplication, not matrix multiplication\n",
    "print(row/row.T) # elementwise division, not matrix division\n",
    "print(row.T/row) # elementwise division, not matrix division\n",
    "print(row/row) # elementwise division, not matrix division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[285]]\n",
      "[[ 1  2  3  4  5  6  7  8  9]\n",
      " [ 2  4  6  8 10 12 14 16 18]\n",
      " [ 3  6  9 12 15 18 21 24 27]\n",
      " [ 4  8 12 16 20 24 28 32 36]\n",
      " [ 5 10 15 20 25 30 35 40 45]\n",
      " [ 6 12 18 24 30 36 42 48 54]\n",
      " [ 7 14 21 28 35 42 49 56 63]\n",
      " [ 8 16 24 32 40 48 56 64 72]\n",
      " [ 9 18 27 36 45 54 63 72 81]]\n",
      "[[ 1]\n",
      " [ 4]\n",
      " [ 9]\n",
      " [16]\n",
      " [25]\n",
      " [36]\n",
      " [49]\n",
      " [64]\n",
      " [81]]\n",
      "[[1.         0.5        0.33333333 0.25       0.2        0.16666667\n",
      "  0.14285714 0.125      0.11111111]\n",
      " [2.         1.         0.66666667 0.5        0.4        0.33333333\n",
      "  0.28571429 0.25       0.22222222]\n",
      " [3.         1.5        1.         0.75       0.6        0.5\n",
      "  0.42857143 0.375      0.33333333]\n",
      " [4.         2.         1.33333333 1.         0.8        0.66666667\n",
      "  0.57142857 0.5        0.44444444]\n",
      " [5.         2.5        1.66666667 1.25       1.         0.83333333\n",
      "  0.71428571 0.625      0.55555556]\n",
      " [6.         3.         2.         1.5        1.2        1.\n",
      "  0.85714286 0.75       0.66666667]\n",
      " [7.         3.5        2.33333333 1.75       1.4        1.16666667\n",
      "  1.         0.875      0.77777778]\n",
      " [8.         4.         2.66666667 2.         1.6        1.33333333\n",
      "  1.14285714 1.         0.88888889]\n",
      " [9.         4.5        3.         2.25       1.8        1.5\n",
      "  1.28571429 1.125      1.        ]]\n",
      "[[1.         2.         3.         4.         5.         6.\n",
      "  7.         8.         9.        ]\n",
      " [0.5        1.         1.5        2.         2.5        3.\n",
      "  3.5        4.         4.5       ]\n",
      " [0.33333333 0.66666667 1.         1.33333333 1.66666667 2.\n",
      "  2.33333333 2.66666667 3.        ]\n",
      " [0.25       0.5        0.75       1.         1.25       1.5\n",
      "  1.75       2.         2.25      ]\n",
      " [0.2        0.4        0.6        0.8        1.         1.2\n",
      "  1.4        1.6        1.8       ]\n",
      " [0.16666667 0.33333333 0.5        0.66666667 0.83333333 1.\n",
      "  1.16666667 1.33333333 1.5       ]\n",
      " [0.14285714 0.28571429 0.42857143 0.57142857 0.71428571 0.85714286\n",
      "  1.         1.14285714 1.28571429]\n",
      " [0.125      0.25       0.375      0.5        0.625      0.75\n",
      "  0.875      1.         1.125     ]\n",
      " [0.11111111 0.22222222 0.33333333 0.44444444 0.55555556 0.66666667\n",
      "  0.77777778 0.88888889 1.        ]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(col.T@col) # Correct -> produces a single scalar. The transposed column vector is a row. Multiplying a matrix row * column yields a scalar.\n",
    "print(col.T*col) # Multiplies it elementwise.\n",
    "print(col*col)\n",
    "print(col/col.T)\n",
    "print(col.T/col)\n",
    "print(col/col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  9]\n",
      " [ 2  4  6  8 10 12 14 16 18]\n",
      " [ 3  6  9 12 15 18 21 24 27]\n",
      " [ 4  8 12 16 20 24 28 32 36]\n",
      " [ 5 10 15 20 25 30 35 40 45]\n",
      " [ 6 12 18 24 30 36 42 48 54]\n",
      " [ 7 14 21 28 35 42 49 56 63]\n",
      " [ 8 16 24 32 40 48 56 64 72]\n",
      " [ 9 18 27 36 45 54 63 72 81]]\n",
      "[[ 1  2  3  4  5  6  7  8  9]\n",
      " [ 2  4  6  8 10 12 14 16 18]\n",
      " [ 3  6  9 12 15 18 21 24 27]\n",
      " [ 4  8 12 16 20 24 28 32 36]\n",
      " [ 5 10 15 20 25 30 35 40 45]\n",
      " [ 6 12 18 24 30 36 42 48 54]\n",
      " [ 7 14 21 28 35 42 49 56 63]\n",
      " [ 8 16 24 32 40 48 56 64 72]\n",
      " [ 9 18 27 36 45 54 63 72 81]]\n",
      "[nan  1.  1.  1.  1.  1.  1.  1.]\n",
      "[[1.         2.         3.         4.         5.         6.\n",
      "  7.         8.         9.        ]\n",
      " [0.5        1.         1.5        2.         2.5        3.\n",
      "  3.5        4.         4.5       ]\n",
      " [0.33333333 0.66666667 1.         1.33333333 1.66666667 2.\n",
      "  2.33333333 2.66666667 3.        ]\n",
      " [0.25       0.5        0.75       1.         1.25       1.5\n",
      "  1.75       2.         2.25      ]\n",
      " [0.2        0.4        0.6        0.8        1.         1.2\n",
      "  1.4        1.6        1.8       ]\n",
      " [0.16666667 0.33333333 0.5        0.66666667 0.83333333 1.\n",
      "  1.16666667 1.33333333 1.5       ]\n",
      " [0.14285714 0.28571429 0.42857143 0.57142857 0.71428571 0.85714286\n",
      "  1.         1.14285714 1.28571429]\n",
      " [0.125      0.25       0.375      0.5        0.625      0.75\n",
      "  0.875      1.         1.125     ]\n",
      " [0.11111111 0.22222222 0.33333333 0.44444444 0.55555556 0.66666667\n",
      "  0.77777778 0.88888889 1.        ]]\n",
      "[[1.         0.5        0.33333333 0.25       0.2        0.16666667\n",
      "  0.14285714 0.125      0.11111111]\n",
      " [2.         1.         0.66666667 0.5        0.4        0.33333333\n",
      "  0.28571429 0.25       0.22222222]\n",
      " [3.         1.5        1.         0.75       0.6        0.5\n",
      "  0.42857143 0.375      0.33333333]\n",
      " [4.         2.         1.33333333 1.         0.8        0.66666667\n",
      "  0.57142857 0.5        0.44444444]\n",
      " [5.         2.5        1.66666667 1.25       1.         0.83333333\n",
      "  0.71428571 0.625      0.55555556]\n",
      " [6.         3.         2.         1.5        1.2        1.\n",
      "  0.85714286 0.75       0.66666667]\n",
      " [7.         3.5        2.33333333 1.75       1.4        1.16666667\n",
      "  1.         0.875      0.77777778]\n",
      " [8.         4.         2.66666667 2.         1.6        1.33333333\n",
      "  1.14285714 1.         0.88888889]\n",
      " [9.         4.5        3.         2.25       1.8        1.5\n",
      "  1.28571429 1.125      1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nc/mxht2rvj70z567nmv3cxrryc0000gn/T/ipykernel_18470/1316177879.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  print(x/x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(row*col)\n",
    "print(col*row)\n",
    "print(x/x)\n",
    "print(row/col)\n",
    "print(col/row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OLS we need to be able to calculate the inverse. This is done with the `linalg` submodule. Create a new matrix that we can calculate the inverse on. Why can't we take the inverse of `x`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'numpy.linalg' from '/Users/noahcarelse/Library/CloudStorage/ProtonDrive-noahcarelse@protonmail.com-folder/Offline mappe/Universitet/01 - Cand polit/1. semester/01 - Advanced Microeconometrics/Advanced-Microeconometrics-UCPH-2025/.venv/lib/python3.13/site-packages/numpy/linalg/__init__.py'>\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg) # a function of numpy\n",
    "print(x)\n",
    "#x_inv = np.linalg.inv(x) # this doesn't work since x is not a square matrix, its a 1x9 matrix.\n",
    "\n",
    "\n",
    "# A correct example:\n",
    "y = np.array([[1, 2], [3, 4]])\n",
    "y_inv = np.linalg.inv(y) # FILL IN HERE\n",
    "print(y)\n",
    "print(y_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we normally need to check before we take the inverse? What `numpy.linalg` methods can we use to help us check for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, check whether the matrix is square, singlular or non-singular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack vectors or matrices together\n",
    "If you have several 1-D vectors (has the shape (k,)), you can use `np.column_stack()` to get a matrix with the input vectors put together as column.\n",
    "\n",
    "If you have matrices (or arrays) that are multidimensional (have the shape (k, t)), you can use `np.hstack()` (means horizontal stack). This is very useful if you already have a matrix, and you want to add a vector.\n",
    "\n",
    "(i) Try to make a matrix with two `row` vectors, this should give you a $9 \\times 2$ vector.\n",
    "\n",
    "(ii) Make a new vector, and add it to the `x` matrix. This should then be a $3 \\times 4$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]\n",
      " [5 5]\n",
      " [6 6]\n",
      " [7 7]\n",
      " [8 8]\n",
      " [9 9]]\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 1],\n",
       "       [3, 4, 5, 2],\n",
       "       [6, 7, 8, 3]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i)\n",
    "print(row)\n",
    "stacked_row_col = np.column_stack((row, row)) # Takes the row vector and makes it a column, then stacks it next to col.\n",
    "print(stacked_row_col)\n",
    "print(\" \")\n",
    "\n",
    "\n",
    "# ii) Make a new vector, and add it to the x matrix. This should be a 3 times 4 matrix.\n",
    "# so 3 x 4 matrix.\n",
    "x = np.arange(9) # the arange(9) produces 0 - 8 -> 9 elements\n",
    "y = np.array([[1],[2],[3]]) # produce a 3x1 matrix (KxT = column x rows)\n",
    "np.hstack((x.reshape(3,3), y)) # FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other methods that you need to know.\n",
    "The numpy library is vast. Some other methods that are useful are `ones`, `diag`, `diagonal`, `eye`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Data generation\n",
    "### 1.1 \n",
    "Create a synthetic dataset with the following characteristics\n",
    "\n",
    "\\begin{align}\n",
    "    y_i &= \\beta_0 + x_{1i}\\beta_1 + x_{2i}\\beta_2 + \\varepsilon_i\n",
    "\\end{align}\n",
    "\n",
    "where $\\beta_0=1$, $\\beta_1 = -0.5$, $\\beta_2 = 2$, $x_{1i} \\sim \\mathcal{N}(0, 4)$, $x_{2i} \\sim \\mathcal{N}(5, 9)$, $\\varepsilon_i \\sim \\mathcal{N}(0, 1)$, and $(x_{1i},x_{2i})$ and $\\varepsilon_i$ are independent, and where $i = 0, ..., 99$. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create a seed to always have identical draws.\n",
    "# Instance a random number generator using this seed.\n",
    "seed = 42\n",
    "rng = random.default_rng(seed=seed) # rng generator\n",
    "n = 100 # draws\n",
    "b = np.array([1, -0.5, 2]).reshape(-1, 1) # beta\n",
    "\n",
    "\n",
    "# Make random draws from a normal distribution.\n",
    "def random_draws(n):\n",
    "    x0 = np.ones(n).reshape(-1,1) # Have to reshape for to a column. x_0 is the constant, but not shown directly in the equation.\n",
    "    x1 = rng.normal(size=n,loc=0,scale=2).reshape(-1,1) \n",
    "    x2 = rng.normal(size=n,loc=5,scale=3).reshape(-1,1)\n",
    "    eps = rng.standard_normal(n).reshape(-1,1) # error term\n",
    "    \n",
    "    # Stack the single columns into a matrix, \n",
    "    X = np.hstack((x0, x1, x2)) \n",
    "    \n",
    "    return X, eps\n",
    "\n",
    "\n",
    "\n",
    "X, eps = random_draws(n)\n",
    "\n",
    "# Create y using the betas, X and eps.\n",
    "y = X@b + eps \n",
    "\n",
    "# Does y have the dimensions you expect?\n",
    "print(y.shape) # yes. 100 entries in a column matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 \n",
    "Imagine that you had not generated the dataset yourself, but that you were given a similar data set that was already collected (generated) and ready to analyze. What would you observe and not observe in that data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible missing data entries? Or the set seed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - OLS\n",
    "### 2.1\n",
    "Remember the mathematical equation for OLS estimation, as we will later use it to estimate the beta coefficients with the data from the previous exercise.<br>\n",
    "**Write out the OLS estimator in matrix form:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\boldsymbol{\\beta}} = \\mathbf{X'X}^{-1} \\mathbf{X'Y} $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Look it up on p.57 in Wooldridge*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "To perform inference on the OLS estimators, we need to calculate the standard errors for the previously estimates OLS coefficients. Again, make sure you remember its equation, *and write up the OLS standard errors in matrix form:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{\\widehat{Var(\\boldsymbol{\\hat{\\beta}})}} = \\hat{\\sigma}^2 \\mathbf{X'X}^{-1}$, for $\\hat{\\sigma}^2 = SSR/(N-K)$, <br>\n",
    "\n",
    "where $SSR = \\sum_{i=0}^{N - 1} \\hat{u}^2_i$, $N$ is the number of observations, and $K$ is the number of explanatory variables including the constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Look it up on p.60 in Wooldridge* <br>\n",
    "*Hint: Remember that the variance estimate is a function of $\\hat{\\sigma}^2$, which is calculated using SSR*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "Estimate $\\boldsymbol{\\hat{\\beta}}$ from the synthetic data set. Furthermore, calculate standard errors and t-values (assuming that the assumptions of the classical linear regression model are satisfied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_hat values: \n",
      "[[ 0.91355184]\n",
      " [-0.50537828]\n",
      " [ 2.0047447 ]]\n",
      "Standard errors: \n",
      "[[0.20537787]\n",
      " [0.06725774]\n",
      " [0.03555339]]\n",
      "t-values: \n",
      "[[ 4.44815138]\n",
      " [-7.51405441]\n",
      " [56.38687539]]\n",
      "residuals: \n",
      "[[ 4.08959719e-01]\n",
      " [ 1.44052651e+00]\n",
      " [ 1.66452937e-01]\n",
      " [ 7.06282818e-01]\n",
      " [-1.99514466e+00]\n",
      " [ 2.92349968e-03]\n",
      " [-7.65607777e-01]\n",
      " [-1.15466425e+00]\n",
      " [-8.27569468e-01]\n",
      " [-2.55987744e-01]\n",
      " [ 9.81902865e-01]\n",
      " [-1.25868565e+00]\n",
      " [ 1.02523605e-01]\n",
      " [-3.88736198e-01]\n",
      " [-2.60946344e-01]\n",
      " [ 1.06377630e+00]\n",
      " [ 6.01494646e-01]\n",
      " [ 1.38949744e+00]\n",
      " [-1.05131807e-01]\n",
      " [-6.30347973e-01]\n",
      " [-1.48554073e-01]\n",
      " [ 2.95345158e-01]\n",
      " [ 2.49316900e-01]\n",
      " [-1.04267244e+00]\n",
      " [ 1.36720042e-01]\n",
      " [ 2.82085500e-01]\n",
      " [ 2.56509570e+00]\n",
      " [ 1.96042117e+00]\n",
      " [-7.76972820e-01]\n",
      " [-2.06835573e-01]\n",
      " [-1.37213199e+00]\n",
      " [-5.12758091e-01]\n",
      " [ 3.63778884e-01]\n",
      " [ 1.26298802e+00]\n",
      " [-6.38797749e-01]\n",
      " [-5.64822064e-01]\n",
      " [-2.09025265e+00]\n",
      " [-1.20908441e-01]\n",
      " [-1.03698002e+00]\n",
      " [-5.01192854e-01]\n",
      " [-8.12040010e-01]\n",
      " [-1.16102360e-02]\n",
      " [-1.67181456e+00]\n",
      " [-1.40563396e+00]\n",
      " [ 2.20479840e+00]\n",
      " [-1.21643335e+00]\n",
      " [-1.01597469e+00]\n",
      " [ 1.90404734e+00]\n",
      " [ 2.95992133e+00]\n",
      " [-1.11035050e+00]\n",
      " [-3.00156345e-01]\n",
      " [ 4.25812302e-01]\n",
      " [ 1.79958593e+00]\n",
      " [-9.20648828e-01]\n",
      " [-1.86847236e-01]\n",
      " [ 8.08025203e-01]\n",
      " [ 4.92676805e-01]\n",
      " [-3.11339404e-01]\n",
      " [-7.33046482e-02]\n",
      " [-1.28488919e+00]\n",
      " [-1.79813407e-01]\n",
      " [-1.96942101e-01]\n",
      " [ 2.66348347e-01]\n",
      " [-4.74605122e-01]\n",
      " [ 5.29978388e-01]\n",
      " [ 1.09682652e+00]\n",
      " [ 2.01142793e-01]\n",
      " [ 4.04028316e-01]\n",
      " [ 1.27338475e-01]\n",
      " [ 6.13314906e-02]\n",
      " [-6.63235059e-01]\n",
      " [ 3.60679205e-01]\n",
      " [-3.79758049e-02]\n",
      " [ 2.17868611e+00]\n",
      " [ 1.65580187e+00]\n",
      " [ 4.53541823e-01]\n",
      " [-7.27405274e-01]\n",
      " [-1.05025881e+00]\n",
      " [ 1.26228552e+00]\n",
      " [ 3.18077897e-01]\n",
      " [ 5.29191625e-01]\n",
      " [-1.69210409e+00]\n",
      " [ 9.92107108e-01]\n",
      " [ 4.97291777e-01]\n",
      " [-1.06667212e+00]\n",
      " [-4.25422114e-01]\n",
      " [ 3.18784527e-01]\n",
      " [ 1.32755069e-01]\n",
      " [-2.04800827e-01]\n",
      " [-5.94599534e-02]\n",
      " [-2.06630305e-01]\n",
      " [ 2.16783098e-01]\n",
      " [ 1.53511772e+00]\n",
      " [-2.52559363e+00]\n",
      " [-1.76517721e-01]\n",
      " [ 2.36406761e-01]\n",
      " [ 3.35333765e-01]\n",
      " [-3.14300021e-01]\n",
      " [-1.68962402e+00]\n",
      " [ 3.83306762e-01]]\n"
     ]
    }
   ],
   "source": [
    "def ols_estimation(y, X):\n",
    "    # Make sure that y and X are 2-D.\n",
    "    y = y.reshape(-1, 1)\n",
    "    if len(X.shape)<2:\n",
    "        X = X.reshape(-1, 1)\n",
    "\n",
    "    # Estimate beta\n",
    "    b_hat =  la.inv(X.T@X)@X.T@y  # Fill in here\n",
    "\n",
    "    # Calculate standard errors\n",
    "    residual = y - X@b_hat\n",
    "    sigma = residual.T @ residual / (residual.shape[0] - b.shape[0]) # output is a column with one entry.\n",
    "    #print(sigma[0][0]) # \n",
    "    varb = sigma[0][0] * la.inv(X.T@X) # the covariance matrix, diagonal is variance. The scalar for sigma is at entry [0][0], else it throws a matmul error.\n",
    "    se = np.sqrt(varb.diagonal().reshape(-1,1)) # reshape so it can fit into the t_value calculations.\n",
    "\n",
    "    # Calculate t-values\n",
    "    t_values = b_hat/se\n",
    "    \n",
    "    return b_hat, se, t_values, residual\n",
    "\n",
    "\n",
    "b_hat, se, t_values, residual = ols_estimation(y, X)\n",
    "print(\"b_hat values: \\n\" + str(b_hat))\n",
    "print(\"Standard errors: \\n\" + str(se))\n",
    "print(\"t-values: \\n\" + str(t_values))\n",
    "print(\"residuals: \\n\" + str(residual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python stores vectors as one-dimensional rather than two-dimensional objects. This can sometimes cause havoc when we want to compute matrix products. Compute the outer and inner products of the residuals from above using np.inner() and np.outer(). Compare these with your computed outer and inner products when using matrix multiplication @. When computing outer and inner products of a column vector, a, recall that a'a is the inner product and aa' is the outer product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner product, first 5 listings: [ 0.16724805  0.58911732  0.06807255  0.28884122 -0.8159338 ]\n",
      "Outer product, first 5 listings: [ 0.16724805  0.58911732  0.06807255  0.28884122 -0.8159338 ]\n",
      "matrix multiplication broadcast inner: [[103.88122746]]\n",
      "matrix multiplication broadcast outer, first 5 listings: [ 0.16724805  0.58911732  0.06807255  0.28884122 -0.8159338 ]\n",
      "res shape:          (100, 1)\n",
      "inner shape:        (100, 100)\n",
      "outer shape:        (100, 100)\n",
      "matmul_inner shape: (1, 1)\n",
      "matmul_outer shape: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "res = residual\n",
    "inner = np.inner(res, res) # it is still a vector.\n",
    "print(\"Inner product, first 5 listings: \" + str(inner[0][:5])) # a matrix, unexpected behaviour\n",
    "\n",
    "outer = np.outer(res,res)\n",
    "print(\"Outer product, first 5 listings: \" + str(outer[0][:5])) # a matrix, as expected\n",
    "\n",
    "matmul_inner = residual.T@residual\n",
    "print(\"matrix multiplication broadcast inner: \" + str(matmul_inner)) # a scalar but in a matrix, somewhat expected\n",
    "\n",
    "matmul_outer = residual@residual.T\n",
    "print(\"matrix multiplication broadcast outer, first 5 listings: \" + str(matmul_outer[0][:5])) # a matrix, as expected\n",
    "\n",
    "print('res shape:         ', res.shape)\n",
    "print('inner shape:       ', inner.shape)\n",
    "print('outer shape:       ', outer.shape)\n",
    "print('matmul_inner shape:', matmul_inner.shape)\n",
    "print('matmul_outer shape:', matmul_outer.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we flatten the residuals to be stored in Python's default mode (i.e. one-dimensional) what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res shape:          (100,)\n",
      "inner shape:        ()\n",
      "outer shape:        (100, 100)\n",
      "matmul_inner shape: (1, 1)\n",
      "matmul_outer shape: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "res = res.flatten()\n",
    "inner = np.inner(res, res) # a scalar, as expected\n",
    "outer = np.outer(res,res) # a matrix, as expected\n",
    "matmul_inner = residual.T@residual # a scalar, but in a matrix, somewhat expected\n",
    "matmul_outer = residual@residual.T # a matrix, as expected\n",
    "\n",
    "print('res shape:         ', res.shape)\n",
    "print('inner shape:       ', inner.shape)\n",
    "print('outer shape:       ', outer.shape)\n",
    "print('matmul_inner shape:', matmul_inner.shape)\n",
    "print('matmul_outer shape:', matmul_outer.shape)\n",
    "# expected output of the shapes. Matrix multiplication '@' still outputs a matrix, but computes correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written a code to print a table, using the `tabulate` package. You will need to add the row names for this code to work - each row contains a information about the different coefficients on the explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Estimates:\n",
      "\n",
      "        β      β̂      Se    t-value\n",
      "---  ----  ------  -----  ---------\n",
      "b_0   1.0   0.914  0.205        4.4\n",
      "b_1  -0.5  -0.505  0.067       -7.5\n",
      "b_2   2.0   2.005  0.036       56.4\n"
     ]
    }
   ],
   "source": [
    "def print_table(row_names, b, b_hat, se, t_values):\n",
    "    table = []\n",
    "\n",
    "    # Make a list, where each row contains the estimated and calculated values.\n",
    "    for index, name in enumerate(row_names):\n",
    "        table_row = [\n",
    "            name, b[index], b_hat[index], se[index], t_values[index]\n",
    "        ]\n",
    "        table.append(table_row)\n",
    "\n",
    "    # Print the list using the tabulate class.\n",
    "    headers = ['', '\\u03b2', '\\u03b2\\u0302 ', 'Se', 't-value']\n",
    "    print('OLS Estimates:\\n')\n",
    "    print(tabulate(table, headers, floatfmt=['', '.1f', '.3f', '.3f', '.1f']))\n",
    "\n",
    "row_names = [\"b_0\", \"b_1\", \"b_2\"] # Fill in here\n",
    "print_table(row_names, b, b_hat, se, t_values) # Fill in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can print a table which you can paste straight into latex using the following code. This uses panda data frames  which we'll cover next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      " & β & β̂ & se & t-values \\\\\n",
      "beta1 & [1.] & [0.9136] & [0.2054] & [4.4482] \\\\\n",
      "beta2 & [-0.5] & [-0.5054] & [0.0673] & [-7.5141] \\\\\n",
      "beta3 & [2.] & [2.0047] & [0.0356] & [56.3869] \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Note that it also requires the jinja2 package!\n",
    "dat = pd.DataFrame(zip(b,b_hat.round(4),se.round(4),t_values.round(4)))\n",
    "dat.columns = ['\\u03b2','\\u03b2\\u0302','se','t-values']\n",
    "dat.index = ['beta1','beta2','beta3']\n",
    "print(dat.style.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - a simple Monte Carlo Experiment\n",
    "Carry out a Monte Carlo experiment with $S = 200$ replications and $N = 100$ observations to check if the OLS estimator provides an unbiased estimate of $\\boldsymbol{\\beta}$\n",
    "### 3.1\n",
    "Generate 200 data sets similar to what you did in exercise 1, and estimate $\\boldsymbol{\\beta}$ on each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* Start by making prefilling two arrays using `np.zeros`, one array to store the estimated beta coefficients, and one to store the estimated standard errors. What shape should these arrays have?\n",
    "\n",
    "Then make a loop where each loop makes a random draw, and then estimates on this random draw. And finally stores the estimated coefficients and standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables and lists\n",
    "s = 200\n",
    "n = 100\n",
    "\n",
    "# Allocate memory for arrays to later fill\n",
    "b_coeffs = np.zeros((s, b.size))\n",
    "b_ses = np.zeros((s, b.size))\n",
    "\n",
    "for i in range(s):\n",
    "    # Generate data\n",
    "    X, eps = # Fill in here\n",
    "    y = # Fill in here\n",
    "\n",
    "    # Estimate coefficients and variance\n",
    "    b_hat, se, t_values = # Fill in here\n",
    "\n",
    "    # Store estimates\n",
    "    b_coeffs[i, :] = # Fill in here\n",
    "    b_ses[i, :] = # Fill in here\n",
    "\n",
    "# Make sure that there are no more zeros left in the arrays.\n",
    "assert np.all(b_coeffs) and np.all(b_ses), 'Not all coefficients or standard errors are non-zero.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2\n",
    "Do the following three calculations:\n",
    "- Calculate the means of the estimates (means across simulations)\n",
    "- Calculate the means of the standard errors (means across simulations)\n",
    "- Calculate the standard error of the MC estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_b_hat = # Fill in here\n",
    "mean_b_se = # Fill in here\n",
    "mean_mc_se = # Fill in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3\n",
    "Draw a histogram for the 200 estimates of $\\beta_1$. This can be done using matplotlib with the method `plt.hist()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
